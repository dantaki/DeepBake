{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bake a Deep Learning Classifier with Keras\n",
    "---------------------------------------------------\n",
    "\n",
    "Keras is a library that simplifies the construction of neural networks.\n",
    "\n",
    "This notebook will highlight how to construct a simple feed-forward neural network to predict the final rankings of bakers from episode 2.\n",
    "\n",
    "The features used in the model include the mean ranking for technical challenges and the ranking of the technical challenge for episode 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import vapeplot\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, Dropout\n",
    "from keras.activations import relu, sigmoid, tanh\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def timestamp(): return datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "def quantile_scale(df,feats):\n",
    "    # force data into a normal distribution\n",
    "    qua = df\n",
    "    scaler = QuantileTransformer(\n",
    "        n_quantiles=10,\n",
    "        random_state=42,\n",
    "        ignore_implicit_zeros=True, #sparse matrix\n",
    "    )\n",
    "    # fit the scaler\n",
    "    scaler.fit(qua[feats])\n",
    "    # transform values\n",
    "    qua[feats] = scaler.transform(qua[feats])\n",
    "    return qua\n",
    "\n",
    "def calc_95ci(a,confidence=0.95):\n",
    "    a = 1.0 * np.array(a)\n",
    "    n = len(a)\n",
    "    m, se = np.nanmean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return h\n",
    "\n",
    "def return_feats(df,feats,label):\n",
    "    # returns a matrix of features and labels\n",
    "    df = df.sample(frac=1.)\n",
    "    X = np.matrix(df[feats])\n",
    "    y = np.array(df[label])\n",
    "    return X,y\n",
    "# functions to transform class labels into tiers\n",
    "def transform_labels(classes):\n",
    "    \"\"\"converts all places >=8 to 8\"\"\"\n",
    "    return np.where(classes<=7, classes, 8)\n",
    "def tiered(classes):\n",
    "    \"\"\"\n",
    "    0 = 1st place\n",
    "    1 = runner-ups\n",
    "    2 = 3rd-4th place\n",
    "    3 = 5th-7th place\n",
    "    4 = 8th and below\n",
    "    \"\"\"\n",
    "    trans = []\n",
    "    for x in classes:\n",
    "        if x==1: c=0\n",
    "        if x==2: c=1\n",
    "        if x>=3 and x<=4: c=2\n",
    "        if x>=5 and x<=7: c=3\n",
    "        if x>=8: c=4\n",
    "        trans.append(c)\n",
    "    return trans\n",
    "\n",
    "def _4tiers(classes):\n",
    "    \"\"\"\n",
    "    0 = 1st and runner-up    \n",
    "    1 = 3rd-4th place \n",
    "    rest follows tiered()\n",
    "    \"\"\"\n",
    "    trans = []\n",
    "    for x in classes:\n",
    "        if x<=2: c=0\n",
    "        if x>=3 and x<=4: c=1\n",
    "        if x>=5 and x<=7: c=2\n",
    "        if x>=8: c=3\n",
    "        trans.append(c)\n",
    "    return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# episode 2 classifier\n",
    "episode=2\n",
    "season=7\n",
    "\n",
    "tech = pd.read_csv(\"../RESULTS/gbbo.features.20190909.tsv\",sep='\\t')\n",
    "feats = ['tech_mean','tech','mean_star','star','mean_good','good','mean_bad','bad']\n",
    "\n",
    "# transform class labels into tiers\n",
    "classes = tiered(np.array(tech['place']))\n",
    "tech['place']=classes\n",
    "tech = tech.loc[tech['episode']==episode]\n",
    "\n",
    "# noramlize features\n",
    "tech = quantile_scale(tech,feats)\n",
    "X,y = return_feats(tech,feats,'place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "input_shape = [np.matrix(X).shape[1]]\n",
    "output_shape = [len(set(y))]\n",
    "\n",
    "\"\"\"\n",
    "nl[1-3]:\n",
    "the number of hidden neural layers.\n",
    "this function takes a combination of different \n",
    "parameters to construct networks with varying dimensions\n",
    "----------------------------------------------------\n",
    "number of hidden layers =  1 - sum(max(nl1,nl2,nl3))\n",
    "\n",
    "nn[1-3]: \n",
    "the number of neurons to spawn for each hidden layer\n",
    "this variable is paired to nl, so nl1 layer will have nn1 neurons\n",
    "\"\"\"\n",
    "\n",
    "def create_model( nl1=1, nl2=1,  nl3=1, \n",
    "                 nn1=1000, nn2=500, nn3 = 200, lr=0.01, decay=0., l1=0.01, l2=0.01,\n",
    "                act = 'relu', dropout=0,input_shape=input_shape,output_shape=output_shape):\n",
    "    \n",
    "    '''This is a model generating function so that we can search over neural net \n",
    "    parameters and architecture\n",
    "    https://www.kaggle.com/arrogantlymodest/randomised-cv-search-over-keras-neural-network\n",
    "    '''\n",
    "\n",
    "    opt = keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999,  decay=decay)\n",
    "    reg = keras.regularizers.l1_l2(l1=l1, l2=l2)\n",
    "                                                     \n",
    "    model = Sequential()\n",
    "    \n",
    "    # for the first layer we need to specify the input dimensions\n",
    "    first=True\n",
    "    \n",
    "    for i in range(nl1):\n",
    "        if first:\n",
    "            model.add(Dense(nn1, input_dim=input_shape, activation=act, kernel_regularizer=reg))\n",
    "            first=False\n",
    "        else: \n",
    "            model.add(Dense(nn1, activation=act, kernel_regularizer=reg))\n",
    "        if dropout!=0:\n",
    "            model.add(Dropout(dropout))\n",
    "            \n",
    "    for i in range(nl2):\n",
    "        if first:\n",
    "            model.add(Dense(nn2, input_dim=input_shape, activation=act, kernel_regularizer=reg))\n",
    "            first=False\n",
    "        else: \n",
    "            model.add(Dense(nn2, activation=act, kernel_regularizer=reg))\n",
    "        if dropout!=0:\n",
    "            model.add(Dropout(dropout))\n",
    "            \n",
    "    for i in range(nl3):\n",
    "        if first:\n",
    "            model.add(Dense(nn3, input_dim=input_shape, activation=act, kernel_regularizer=reg))\n",
    "            first=False\n",
    "        else: \n",
    "            model.add(Dense(nn3, activation=act, kernel_regularizer=reg))\n",
    "        if dropout!=0:\n",
    "            model.add(Dropout(dropout))\n",
    "            \n",
    "    model.add(Dense(output_shape, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'],)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "----------------------\n",
    "\n",
    "Hyperparameters are model settings that are defined before training. \n",
    "For Neural Networks, this include the learning rate, the number of hidden layers, number of neurons in hidden layers, and neuron activation functions\n",
    "\n",
    "We will evaluate the performance of a neural network across different hyperparameter conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Baker Classes: [5]\n"
     ]
    }
   ],
   "source": [
    "print('Number of Baker Classes: {}'.format(output_shape))\n",
    "\n",
    "#################\n",
    "# learning algorithm parameters\n",
    "lr=[1e-2, 1e-3, 1e-4]\n",
    "decay=[1e-6,1e-9,0]\n",
    "activation=['relu', 'sigmoid']\n",
    "# numbers of layers\n",
    "nl1 = [0,1,2,3,4]\n",
    "nl2 = [0,1,2,3,4]\n",
    "nl3 = [0,1,2,3,4]\n",
    "# neurons in each layer\n",
    "nn1=[2,4,8,16,32,64,128,300,700,1400,2100]\n",
    "nn2=[10,100,400,800]\n",
    "nn3=[10,50,150,300]\n",
    "# dropout and regularisation\n",
    "dropout = [0, 0.1, 0.2, 0.3,0.5]\n",
    "l1 = [0, 0.01, 0.003, 0.001,0.0001]\n",
    "l2 = [0, 0.01, 0.003, 0.001,0.0001]\n",
    "################\n",
    "EPOCHS, BATCH = 25, 36\n",
    "param_grid = dict(\n",
    "                    nl1=nl1, nl2=nl2, nl3=nl3, nn1=nn1, nn2=nn2, nn3=nn3,\n",
    "                    act=activation, l1=l1, l2=l2, lr=lr, decay=decay, dropout=dropout, \n",
    "                    input_shape=input_shape, output_shape = output_shape,\n",
    "                 )\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=EPOCHS, batch_size=BATCH, verbose=0)\n",
    "# Leave One (Season) Out Cross Validation\n",
    "# leave one out CV\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "loo = LeaveOneGroupOut()\n",
    "cv=loo.split(X,groups=tech['season'])\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model, cv=cv, param_distributions=param_grid, \n",
    "                          verbose=10,  n_iter=10, n_jobs=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the Leave One Out Cross Validation over all the different combinations of hyperparameters. \n",
    "\n",
    "-------------------------------------------------\n",
    "#### This will take a while so let it bake!\n",
    "-------------------------------------------------\n",
    "\n",
    "#### Results\n",
    "--------------------\n",
    " 0.3301886835328813 \n",
    "\n",
    "epochs = 6, batch_size = 20\n",
    "{'output_shape': 5, 'nn3': 150, 'nn2': 10, 'nn1': 16, 'nl3': 0, 'nl2': 4, 'nl1': 0, 'lr': 0.01, 'l2': 0, 'l1': 0.003, 'input_shape': 8, 'dropout': 0, 'decay': 1e-06, 'act': 'sigmoid'}\n",
    "\n",
    " 0.36792453462785146 \n",
    " \n",
    "epochs = 100, batch_size = 24\n",
    "{'output_shape': 5, 'nn3': 50, 'nn2': 100, 'nn1': 32, 'nl3': 1, 'nl2': 1, 'nl1': 0, 'lr': 0.01, 'l2': 0, 'l1': 0.01, 'input_shape': 8, 'dropout': 0.2, 'decay': 1e-06, 'act': 'relu'}\n",
    "\n",
    "---------------------------------------------\n",
    "\n",
    " 0.48113208053246986 \n",
    " \n",
    " epochs = 25 batch_size=36\n",
    "{'output_shape': 5, 'nn3': 300, 'nn2': 400, 'nn1': 128, 'nl3': 0, 'nl2': 3, 'nl1': 2, 'lr': 0.001, 'l2': 0.003, 'l1': 0.0001, 'input_shape': 8, 'dropout': 0.3, 'decay': 0, 'act': 'relu'}\n",
    "\n",
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 9 folds for each of 10 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:   51.2s\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=8)]: Done  85 out of  90 | elapsed:  2.0min remaining:    6.9s\n",
      "[Parallel(n_jobs=8)]: Done  90 out of  90 | elapsed:  2.1min finished\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "\n",
      " 0.48113208053246986 \n",
      "\n",
      "{'output_shape': 5, 'nn3': 300, 'nn2': 400, 'nn1': 128, 'nl3': 0, 'nl2': 3, 'nl1': 2, 'lr': 0.001, 'l2': 0.003, 'l1': 0.0001, 'input_shape': 8, 'dropout': 0.3, 'decay': 0, 'act': 'relu'}\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-'*45)\n",
    "print('\\n',grid_result.best_score_,'\\n')\n",
    "print(grid_result.best_params_)\n",
    "print('-'*45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_shape': 5,\n",
       " 'nn3': 300,\n",
       " 'nn2': 400,\n",
       " 'nn1': 128,\n",
       " 'nl3': 0,\n",
       " 'nl2': 3,\n",
       " 'nl1': 2,\n",
       " 'lr': 0.001,\n",
       " 'l2': 0.003,\n",
       " 'l1': 0.0001,\n",
       " 'input_shape': 8,\n",
       " 'dropout': 0.3,\n",
       " 'decay': 0,\n",
       " 'act': 'relu'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = grid_result.best_params_\n",
    "l1 = 0.0001\n",
    "l2 = 0\n",
    "lr = 0.0001\n",
    "nl1 = 0\n",
    "nl2 = 2\n",
    "nl3 = 2\n",
    "nn1 = 2100\n",
    "nn2 = 10\n",
    "nn3 = 300\n",
    "dropout = 0.3\n",
    "decay = 0\n",
    "act='relu'\n",
    "n_dims = np.matrix(X).shape[1]\n",
    "n_classes = len(set(y))\n",
    "clf = create_model( nl1=nl1, nl2=nl2,  nl3=nl3, \n",
    "                     nn1=nn1, nn2=nn2, nn3 = nn3, \n",
    "                     lr=lr, decay=decay, l1=l1, l2=l2,\n",
    "                     act = act, dropout=dropout,\n",
    "                     input_shape=n_dims,\n",
    "                     output_shape=n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 10)                90        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 475\n",
      "Trainable params: 475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 1.8968 - acc: 0.2453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8064397d90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.summary()\n",
    "clf.fit(X, y, validation_split=0.2, batch_size=24, epochs=100, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 9 folds for each of 10 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=8)]: Done  85 out of  90 | elapsed:  9.2min remaining:   32.6s\n",
      "[Parallel(n_jobs=8)]: Done  90 out of  90 | elapsed:  9.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "\n",
      " 0.36792452886419474 \n",
      "\n",
      "{'output_shape': 5, 'nn3': 8, 'nn2': 4, 'nn1': 300, 'nl3': 2, 'nl2': 2, 'nl1': 2, 'lr': 0.01, 'l2': 0, 'l1': 0.001, 'input_shape': 8, 'dropout': 0.2, 'decay': 1e-09, 'act': 'relu'}\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# now iterate the number of neurons per layer\n",
    "#################\n",
    "# learning algorithm parameters\n",
    "lr=[1e-2, 1e-3, 1e-4]\n",
    "decay=[1e-6,1e-9,0]\n",
    "activation=['relu', 'sigmoid']\n",
    "# numbers of layers\n",
    "nl1 = [2,3,4]\n",
    "nl2 = [2,3,4]\n",
    "nl3 = [0,1,2,3,4]\n",
    "# neurons in each layer\n",
    "nn1=[2,4,8,16,32,64,128,300,512,700,1024,1400,2048,2100,2500]\n",
    "nn2=nn1\n",
    "nn3=nn1\n",
    "# dropout and regularisation\n",
    "dropout = [0, 0.1, 0.2, 0.3,0.5]\n",
    "l1 = [0, 0.01, 0.003, 0.001,0.0001]\n",
    "l2 = [0, 0.01, 0.003, 0.001,0.0001]\n",
    "################\n",
    "EPOCHS, BATCH = 25, 36\n",
    "param_grid = dict(\n",
    "                    nl1=nl1, nl2=nl2, nl3=nl3, nn1=nn1, nn2=nn2, nn3=nn3,\n",
    "                    act=activation, l1=l1, l2=l2, lr=lr, decay=decay, dropout=dropout, \n",
    "                    input_shape=input_shape, output_shape = output_shape,\n",
    "                 )\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=EPOCHS, batch_size=BATCH, verbose=0)\n",
    "loo = LeaveOneGroupOut()\n",
    "cv=loo.split(X,groups=tech['season'])\n",
    "grid_2cv = RandomizedSearchCV(estimator=model, cv=cv, param_distributions=param_grid, \n",
    "                          verbose=10,  n_iter=10, n_jobs=8)\n",
    "grid_2nd = grid_2cv.fit(X,y)\n",
    "print('-'*45)\n",
    "print('\\n',grid_2nd.best_score_,'\\n')\n",
    "print(grid_2nd.best_params_)\n",
    "print('-'*45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_shape': 5,\n",
       " 'nn3': 8,\n",
       " 'nn2': 4,\n",
       " 'nn1': 300,\n",
       " 'nl3': 2,\n",
       " 'nl2': 2,\n",
       " 'nl1': 2,\n",
       " 'lr': 0.01,\n",
       " 'l2': 0,\n",
       " 'l1': 0.001,\n",
       " 'input_shape': 8,\n",
       " 'dropout': 0.2,\n",
       " 'decay': 1e-09,\n",
       " 'act': 'relu'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_2nd.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = keras.regularizers.l1_l2(l1=0.003, l2=0.0001)\n",
    "opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999,  decay=1e-09)\n",
    "\n",
    "best_clf = Sequential([\n",
    "    \n",
    "    Dense(800, input_shape=(2, ), activation='relu',kernel_regularizer=best_reg),\n",
    "    Dropout(0.1),\n",
    "    Dense(800, activation='relu',kernel_regularizer=best_reg),\n",
    "    Dropout(0.1),\n",
    "    Dense(300, activation='relu',kernel_regularizer=best_reg),\n",
    "    Dropout(0.1),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "best_clf.summary()\n",
    "best_clf.compile(optimizer=best_opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "best_clf.fit(X, y, validation_split=0., batch_size=30, epochs=10, shuffle=False, verbose=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 10,\n",
       " 'batch_size': 30,\n",
       " 'verbose': 0,\n",
       " 'output_shape': 5,\n",
       " 'nn3': 300,\n",
       " 'nn2': 800,\n",
       " 'nn1': 2100,\n",
       " 'nl3': 1,\n",
       " 'nl2': 2,\n",
       " 'nl1': 0,\n",
       " 'lr': 0.0001,\n",
       " 'l2': 0.0001,\n",
       " 'l1': 0.0001,\n",
       " 'input_shape': 2,\n",
       " 'dropout': 0.1,\n",
       " 'decay': 1e-06,\n",
       " 'act': 'relu',\n",
       " 'build_fn': <function __main__.create_model(nl1=1, nl2=1, nl3=1, nn1=1000, nn2=500, nn3=200, lr=0.01, decay=0.0, l1=0.01, l2=0.01, act='relu', dropout=0, input_shape=[2], output_shape=[5])>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 3, 3, 4, 4, 0, 3, 1, 2, 4, 4, 1, 3, 4, 4, 2, 4, 4, 2, 4, 4,\n",
       "       1, 3, 0, 3, 0, 4, 4, 2, 4, 1, 3, 3, 4, 4, 3, 3, 1, 1, 4, 2, 3, 4,\n",
       "       3, 4, 2, 0, 3, 4, 2, 4, 1, 3, 1, 4, 0, 4, 2, 2, 3, 3, 3, 2, 2, 3,\n",
       "       4, 2, 4, 2, 3, 0, 4, 3, 1, 3, 4, 2, 1, 0, 1, 4, 1, 1, 4, 3, 1, 4,\n",
       "       2, 4, 4, 3, 0, 2, 0, 1, 2, 2, 4, 4, 3, 1, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
