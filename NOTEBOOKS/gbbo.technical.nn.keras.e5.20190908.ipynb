{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bake a Deep Learning Classifier with Keras\n",
    "---------------------------------------------------\n",
    "\n",
    "Keras is a library that simplifies the construction of neural networks.\n",
    "\n",
    "This notebook will highlight how to construct a simple feed-forward neural network to predict the final rankings of bakers from episode 5.\n",
    "\n",
    "The features used in the model include the mean ranking for technical challenges and the ranking of the technical challenge for episode 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import vapeplot\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, Dropout\n",
    "from keras.activations import relu, sigmoid, tanh\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def timestamp(): return datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "def quantile_scale(df,feats):\n",
    "    qua = df\n",
    "    scaler = QuantileTransformer(\n",
    "        n_quantiles=10,\n",
    "        random_state=42,\n",
    "        ignore_implicit_zeros=True, #sparse matrix\n",
    "    )\n",
    "    # fit the scaler\n",
    "    scaler.fit(qua[feats])\n",
    "    # transform values\n",
    "    qua[feats] = scaler.transform(qua[feats])\n",
    "    return qua\n",
    "\n",
    "def calc_95ci(a,confidence=0.95):\n",
    "    a = 1.0 * np.array(a)\n",
    "    n = len(a)\n",
    "    m, se = np.nanmean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return h\n",
    "\n",
    "def return_feats(df,feats,label):\n",
    "    df = df.sample(frac=1.)\n",
    "    X = np.matrix(df[feats])\n",
    "    y = np.array(df[label])\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "episode=5\n",
    "season=7\n",
    "tech = pd.read_csv(\"../RESULTS/gbbo.techinical.data.20190907.tsv\",sep='\\t')\n",
    "\n",
    "## since the minimum number of bakers for a season is 9 (season 1)\n",
    "## we will convert all places greater than 9 to the value '9'\n",
    "## this keeps the number of possible ranking positions the same (number of classes)\n",
    "classes = np.array(tech['place'])\n",
    "classes = np.where(classes<=7, classes, 8)\n",
    "tech['place']=classes\n",
    "feats = ['tech_mean','tech']\n",
    "tech = tech.loc[tech['episode']==episode]\n",
    "\n",
    "tech = quantile_scale(tech,feats)\n",
    "X,y = return_feats(tech,feats,'place')\n",
    "X_test, y_test = return_feats(tech.loc[tech['season']==season],feats,'place')\n",
    "X_train, y_train = return_feats(tech.loc[tech['season']!=season],feats,'place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def create_model(layers, activations):\n",
    "    n_dims = X.shape[1]\n",
    "    n_classes = len(set(y))\n",
    "    model = Sequential()\n",
    "    for i,nodes in enumerate(layers):\n",
    "        if i==0:\n",
    "            model.add(Dense(n_dims,input_dim=n_dims))\n",
    "            model.add(Activation(activations))\n",
    "        else:\n",
    "            model.add(Dense(nodes))\n",
    "            model.add(Activation(activations))\n",
    "    # output layer needs to have the same number of neurons\n",
    "    # as the number of classes to predict\n",
    "    model.add(Dense(n_classes))\n",
    "    \n",
    "    # binary_crossentropy is for binary models\n",
    "    # categorical_crossentropy is for multiclass models\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "----------------------\n",
    "\n",
    "Hyperparameters are model settings that are defined before training. \n",
    "For Neural Networks, this include the learning rate, the number of hidden layers, number of neurons in hidden layers, and neuron activation functions\n",
    "\n",
    "We will evaluate the performance of a neural network across different hyperparameter conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Bakers: 8\n",
      "N Jobs: 729\n"
     ]
    }
   ],
   "source": [
    "n_dims = np.matrix(X).shape[1]\n",
    "n_classes = len(set(y))\n",
    "print('Number of Bakers: {}'.format(n_classes))\n",
    "\n",
    "#################\n",
    "# hyperparamters\n",
    "## number of hidden layers is the length of the entry\n",
    "## the value is the number of neurons for each layer\n",
    "layers= [[n_dims], [40,20], [45,30,15] ]\n",
    "## activation functions for neurons\n",
    "activations = ['sigmoid','relu','tanh']\n",
    "## number of times the complete dataset is passed through\n",
    "## the model. underfit if too low, overfit if too high\n",
    "epochs = [10,25,50]\n",
    "## size of subset for each epoch, determines the number of\n",
    "## iterations for each epoch\n",
    "batch_size = [10,25,50]\n",
    "################\n",
    "param_grid = dict(\n",
    "    layers=layers,\n",
    "    activations=activations,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size\n",
    "    )\n",
    "\n",
    "# Leave One (Season) Out Cross Validation\n",
    "# leave one out CV\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "loo = LeaveOneGroupOut()\n",
    "cv=loo.split(X,groups=tech['season'])\n",
    "\n",
    "grid = GridSearchCV(estimator=model,\n",
    "                    param_grid=param_grid,\n",
    "                    cv=cv,\n",
    "                    verbose=2,\n",
    "                    n_jobs=8,\n",
    "                   )\n",
    "\n",
    "print('N Jobs:',len(layers)*len(activations)*len(epochs)*len(batch_size)*9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the Leave One Out Cross Validation over all the different combinations of hyperparameters. \n",
    "\n",
    "-------------------------------------------------\n",
    "#### This will take a while so let it bake!\n",
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 9 folds for each of 81 candidates, totalling 729 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=8)]: Done 632 tasks      | elapsed:  6.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 729 out of 729 | elapsed:  8.5min finished\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activations': 'sigmoid', 'batch_size': 50, 'epochs': 50, 'layers': [40, 20]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
