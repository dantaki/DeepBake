{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bake a Deep Learning Classifier with Keras\n",
    "---------------------------------------------------\n",
    "\n",
    "Keras is a library that simplifies the construction of neural networks.\n",
    "\n",
    "This notebook will highlight how to construct a simple feed-forward neural network to predict the final rankings of bakers from episode 2.\n",
    "\n",
    "The features used in the model include the mean ranking for technical challenges and the ranking of the technical challenge for episode 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import vapeplot\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, Dropout\n",
    "from keras.activations import relu, sigmoid, tanh\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def timestamp(): return datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "def quantile_scale(df,feats):\n",
    "    qua = df\n",
    "    scaler = QuantileTransformer(\n",
    "        n_quantiles=10,\n",
    "        random_state=42,\n",
    "        ignore_implicit_zeros=True, #sparse matrix\n",
    "    )\n",
    "    # fit the scaler\n",
    "    scaler.fit(qua[feats])\n",
    "    # transform values\n",
    "    qua[feats] = scaler.transform(qua[feats])\n",
    "    return qua\n",
    "\n",
    "def calc_95ci(a,confidence=0.95):\n",
    "    a = 1.0 * np.array(a)\n",
    "    n = len(a)\n",
    "    m, se = np.nanmean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return h\n",
    "\n",
    "def return_feats(df,feats,label):\n",
    "    df = df.sample(frac=1.)\n",
    "    X = np.matrix(df[feats])\n",
    "    y = np.array(df[label])\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "episode=2\n",
    "season=7\n",
    "tech = pd.read_csv(\"../RESULTS/gbbo.techinical.data.20190907.tsv\",sep='\\t')\n",
    "\n",
    "def transform_labels(classes):\n",
    "    return np.where(classes<=7, classes, 8)\n",
    "\n",
    "def tiered(classes):\n",
    "    trans = []\n",
    "    for x in classes:\n",
    "        if x==1: c=0\n",
    "        if x==2: c=1\n",
    "        if x>=3 and x<=4: c=2\n",
    "        if x>=5 and x<=7: c=3\n",
    "        if x>=8: c=4\n",
    "        trans.append(c)\n",
    "    return trans\n",
    "\n",
    "def _4tiers(classes):\n",
    "    trans = []\n",
    "    for x in classes:\n",
    "        if x<=2: c=0\n",
    "        if x>=3 and x<=4: c=1\n",
    "        if x>=5 and x<=7: c=2\n",
    "        if x>=8: c=3\n",
    "        trans.append(c)\n",
    "    return trans\n",
    "\n",
    "classes = tiered(np.array(tech['place']))\n",
    "\n",
    "tech['place']=classes\n",
    "feats = ['tech_mean','tech']\n",
    "tech = tech.loc[tech['episode']==episode]\n",
    "\n",
    "tech = quantile_scale(tech,feats)\n",
    "X,y = return_feats(tech,feats,'place')\n",
    "X_test, y_test = return_feats(tech.loc[tech['season']==season],feats,'place')\n",
    "X_train, y_train = return_feats(tech.loc[tech['season']!=season],feats,'place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "input_shape = [np.matrix(X).shape[1]]\n",
    "output_shape = [len(set(y))]\n",
    "\n",
    "def create_model( nl1=1, nl2=1,  nl3=1, \n",
    "                 nn1=1000, nn2=500, nn3 = 200, lr=0.01, decay=0., l1=0.01, l2=0.01,\n",
    "                act = 'relu', dropout=0,input_shape=input_shape,output_shape=output_shape):\n",
    "    '''This is a model generating function so that we can search over neural net \n",
    "    parameters and architecture\n",
    "    https://www.kaggle.com/arrogantlymodest/randomised-cv-search-over-keras-neural-network\n",
    "    '''\n",
    "\n",
    "    opt = keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999,  decay=decay)\n",
    "    reg = keras.regularizers.l1_l2(l1=l1, l2=l2)\n",
    "                                                     \n",
    "    model = Sequential()\n",
    "    \n",
    "    # for the firt layer we need to specify the input dimensions\n",
    "    first=True\n",
    "    \n",
    "    for i in range(nl1):\n",
    "        if first:\n",
    "            model.add(Dense(nn1, input_dim=input_shape, activation=act, kernel_regularizer=reg))\n",
    "            first=False\n",
    "        else: \n",
    "            model.add(Dense(nn1, activation=act, kernel_regularizer=reg))\n",
    "        if dropout!=0:\n",
    "            model.add(Dropout(dropout))\n",
    "            \n",
    "    for i in range(nl2):\n",
    "        if first:\n",
    "            model.add(Dense(nn2, input_dim=input_shape, activation=act, kernel_regularizer=reg))\n",
    "            first=False\n",
    "        else: \n",
    "            model.add(Dense(nn2, activation=act, kernel_regularizer=reg))\n",
    "        if dropout!=0:\n",
    "            model.add(Dropout(dropout))\n",
    "            \n",
    "    for i in range(nl3):\n",
    "        if first:\n",
    "            model.add(Dense(nn3, input_dim=input_shape, activation=act, kernel_regularizer=reg))\n",
    "            first=False\n",
    "        else: \n",
    "            model.add(Dense(nn3, activation=act, kernel_regularizer=reg))\n",
    "        if dropout!=0:\n",
    "            model.add(Dropout(dropout))\n",
    "            \n",
    "    model.add(Dense(output_shape, activation='sigmoid'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'],)\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=30, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "----------------------\n",
    "\n",
    "Hyperparameters are model settings that are defined before training. \n",
    "For Neural Networks, this include the learning rate, the number of hidden layers, number of neurons in hidden layers, and neuron activation functions\n",
    "\n",
    "We will evaluate the performance of a neural network across different hyperparameter conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Baker Classes: [5]\n"
     ]
    }
   ],
   "source": [
    "print('Number of Baker Classes: {}'.format(output_shape))\n",
    "\n",
    "#################\n",
    "# learning algorithm parameters\n",
    "lr=[1e-2, 1e-3, 1e-4]\n",
    "decay=[1e-6,1e-9,0]\n",
    "activation=['relu', 'sigmoid']\n",
    "# numbers of layers\n",
    "nl1 = [0,1,2]\n",
    "nl2 = [0,1,2]\n",
    "nl3 = [0,1,2]\n",
    "# neurons in each layer\n",
    "nn1=[50,300,700,1400,2100]\n",
    "nn2=[10,100,400,800]\n",
    "nn3=[10,50,150,300]\n",
    "# dropout and regularisation\n",
    "dropout = [0, 0.1, 0.2, 0.3,0.5]\n",
    "l1 = [0, 0.01, 0.003, 0.001,0.0001]\n",
    "l2 = [0, 0.01, 0.003, 0.001,0.0001]\n",
    "################\n",
    "\n",
    "param_grid = dict(\n",
    "                    nl1=nl1, nl2=nl2, nl3=nl3, nn1=nn1, nn2=nn2, nn3=nn3,\n",
    "                    act=activation, l1=l1, l2=l2, lr=lr, decay=decay, dropout=dropout, \n",
    "                    input_shape=input_shape, output_shape = output_shape,\n",
    "                 )\n",
    "\n",
    "# Leave One (Season) Out Cross Validation\n",
    "# leave one out CV\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "loo = LeaveOneGroupOut()\n",
    "cv=loo.split(X,groups=tech['season'])\n",
    "\n",
    "grid = RandomizedSearchCV(estimator=model, cv=cv, param_distributions=param_grid, \n",
    "                          verbose=10,  n_iter=10, n_jobs=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the Leave One Out Cross Validation over all the different combinations of hyperparameters. \n",
    "\n",
    "-------------------------------------------------\n",
    "#### This will take a while so let it bake!\n",
    "-------------------------------------------------\n",
    "\n",
    "#### Results\n",
    "\n",
    "##### Tiers\n",
    "* epochs 10; 30 batch\n",
    "\n",
    "```\n",
    "{'output_shape': 5,\n",
    " 'nn3': 300,\n",
    " 'nn2': 800,\n",
    " 'nn1': 1400,\n",
    " 'nl3': 1,\n",
    " 'nl2': 1,\n",
    " 'nl1': 1,\n",
    " 'lr': 0.0001,\n",
    " 'l2': 0,\n",
    " 'l1': 0.003,\n",
    " 'input_shape': 2,\n",
    " 'dropout': 0,\n",
    " 'decay': 1e-06,\n",
    " 'act': 'relu'}\n",
    " 0.35922330328561725\n",
    "```\n",
    "\n",
    "* epochs 6; 20 batch; more neurons\n",
    "```\n",
    "{'output_shape': 5,\n",
    " 'nn3': 150,\n",
    " 'nn2': 400,\n",
    " 'nn1': 50,\n",
    " 'nl3': 0,\n",
    " 'nl2': 1,\n",
    " 'nl1': 0,\n",
    " 'lr': 0.001,\n",
    " 'l2': 0,\n",
    " 'l1': 0,\n",
    " 'input_shape': 2,\n",
    " 'dropout': 0,\n",
    " 'decay': 0,\n",
    " 'act': 'relu'}\n",
    " 0.35922330328561725\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 9 folds for each of 10 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:   48.4s\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:   54.1s\n",
      "[Parallel(n_jobs=8)]: Done  85 out of  90 | elapsed:  1.0min remaining:    3.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  90 out of  90 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_shape': 5,\n",
       " 'nn3': 300,\n",
       " 'nn2': 800,\n",
       " 'nn1': 2100,\n",
       " 'nl3': 1,\n",
       " 'nl2': 2,\n",
       " 'nl1': 0,\n",
       " 'lr': 0.0001,\n",
       " 'l2': 0.0001,\n",
       " 'l1': 0.0001,\n",
       " 'input_shape': 2,\n",
       " 'dropout': 0.1,\n",
       " 'decay': 1e-06,\n",
       " 'act': 'relu'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.349514568025626"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 10,\n",
       " 'batch_size': 30,\n",
       " 'verbose': 0,\n",
       " 'output_shape': 5,\n",
       " 'nn3': 300,\n",
       " 'nn2': 800,\n",
       " 'nn1': 2100,\n",
       " 'nl3': 1,\n",
       " 'nl2': 2,\n",
       " 'nl1': 0,\n",
       " 'lr': 0.0001,\n",
       " 'l2': 0.0001,\n",
       " 'l1': 0.0001,\n",
       " 'input_shape': 2,\n",
       " 'dropout': 0.1,\n",
       " 'decay': 1e-06,\n",
       " 'act': 'relu',\n",
       " 'build_fn': <function __main__.create_model(nl1=1, nl2=1, nl3=1, nn1=1000, nn2=500, nn3=200, lr=0.01, decay=0.0, l1=0.01, l2=0.01, act='relu', dropout=0, input_shape=[2], output_shape=[5])>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 800)               2400      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 800)               640800    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 300)               240300    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 1505      \n",
      "=================================================================\n",
      "Total params: 885,005\n",
      "Trainable params: 885,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "Epoch 2/10\n",
      "Epoch 3/10\n",
      "Epoch 4/10\n",
      "Epoch 5/10\n",
      "Epoch 6/10\n",
      "Epoch 7/10\n",
      "Epoch 8/10\n",
      "Epoch 9/10\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe1642e94d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_reg = keras.regularizers.l1_l2(l1=0.0001, l2=0.0001)\n",
    "best_opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999,  decay=1e-09)\n",
    "\n",
    "best_clf = Sequential([\n",
    "    \n",
    "    Dense(800, input_shape=(2, ), activation='relu',kernel_regularizer=best_reg),\n",
    "    Dropout(0.1),\n",
    "    Dense(800, activation='relu',kernel_regularizer=best_reg),\n",
    "    Dropout(0.1),\n",
    "    Dense(300, activation='relu',kernel_regularizer=best_reg),\n",
    "    Dropout(0.1),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "best_clf.summary()\n",
    "best_clf.compile(optimizer=best_opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "best_clf.fit(X, y, validation_split=0., batch_size=30, epochs=10, shuffle=False, verbose=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 3, 3, 4, 4, 0, 3, 1, 2, 4, 4, 1, 3, 4, 4, 2, 4, 4, 2, 4, 4,\n",
       "       1, 3, 0, 3, 0, 4, 4, 2, 4, 1, 3, 3, 4, 4, 3, 3, 1, 1, 4, 2, 3, 4,\n",
       "       3, 4, 2, 0, 3, 4, 2, 4, 1, 3, 1, 4, 0, 4, 2, 2, 3, 3, 3, 2, 2, 3,\n",
       "       4, 2, 4, 2, 3, 0, 4, 3, 1, 3, 4, 2, 1, 0, 1, 4, 1, 1, 4, 3, 1, 4,\n",
       "       2, 4, 4, 3, 0, 2, 0, 1, 2, 2, 4, 4, 3, 1, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
