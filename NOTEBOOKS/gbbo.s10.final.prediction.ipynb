{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import vapeplot \n",
    "from scipy import interp\n",
    "import scipy.stats\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal\n",
    "--------------------\n",
    "\n",
    "The goal of this project is to make a classifier that predicts the final rankings for bakers.\n",
    "The idea is to make a model for each episode and to use data from previous episodes in the model.\n",
    "Therefore, a classifier for episode 1 will likely be bad at predicting the final outcome, but a classifier for episode 5 might accurately predict who will be in the top 3 and who might be eliminated in the next episode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def timestamp(): return datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "def quantile_scale(df,feats):\n",
    "    qua = df\n",
    "    scaler = QuantileTransformer(\n",
    "        n_quantiles=10,\n",
    "        random_state=42,\n",
    "        ignore_implicit_zeros=True, #sparse matrix\n",
    "    )\n",
    "    # fit the scaler\n",
    "    scaler.fit(qua[feats])\n",
    "    # transform values\n",
    "    qua[feats] = scaler.transform(qua[feats])\n",
    "    return qua\n",
    "def tiered(classes):\n",
    "    trans = []\n",
    "    for x in classes:\n",
    "        if x==1: c=0\n",
    "        if x==2: c=1\n",
    "        if x>=3 and x<=4: c=2\n",
    "        if x>=5 and x<=7: c=3\n",
    "        if x>=8: c=4\n",
    "        trans.append(c)\n",
    "    return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>baker</th>\n",
       "      <th>episode</th>\n",
       "      <th>place</th>\n",
       "      <th>tech_mean</th>\n",
       "      <th>tech</th>\n",
       "      <th>mean_star</th>\n",
       "      <th>star</th>\n",
       "      <th>mean_good</th>\n",
       "      <th>good</th>\n",
       "      <th>mean_bad</th>\n",
       "      <th>bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Alice</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Alice</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Alice</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.33</td>\n",
       "      <td>7</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>Alice</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Alice</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.40</td>\n",
       "      <td>6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  baker  episode  place  tech_mean  tech  mean_star  star  mean_good  \\\n",
       "0      10  Alice        1      0       5.00     5       0.00     0       0.00   \n",
       "1      10  Alice        2      0       3.00     1       0.50     1       0.50   \n",
       "2      10  Alice        3      0       4.33     7       0.33     0       0.33   \n",
       "3      10  Alice        4      0       5.25     8       0.25     0       0.25   \n",
       "4      10  Alice        5      0       5.40     6       0.20     0       0.20   \n",
       "\n",
       "   good  mean_bad  bad  \n",
       "0     0      0.00    0  \n",
       "1     1      0.00    0  \n",
       "2     0      0.33    1  \n",
       "3     0      0.25    0  \n",
       "4     0      0.20    0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_col = ['season','baker','index','episode','place']\n",
    "tech = pd.read_csv(\"../RESULTS/gbbo.techinical.data.s10.20191104.tsv\",sep=\"\\t\")\n",
    "star = pd.read_csv(\"../RESULTS/gbbo.starbaker.data.s10.final.tsv\",sep=\"\\t\")\n",
    "gbbo = pd.merge(tech, star,  how='left', left_on=merge_col, right_on =merge_col)\n",
    "gbbo = gbbo[['season','baker','episode','place','tech_mean','tech','mean_star','star','mean_good','good','mean_bad','bad']]\n",
    "gbbo.to_csv(\"../RESULTS/gbbo.features.s10.final.tsv\".format(timestamp()),sep=\"\\t\",index=False)\n",
    "gbbo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>baker</th>\n",
       "      <th>episode</th>\n",
       "      <th>place</th>\n",
       "      <th>tech_mean</th>\n",
       "      <th>tech</th>\n",
       "      <th>mean_star</th>\n",
       "      <th>star</th>\n",
       "      <th>mean_good</th>\n",
       "      <th>good</th>\n",
       "      <th>mean_bad</th>\n",
       "      <th>bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Alice</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>Amelia</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "      <td>Dan</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10</td>\n",
       "      <td>David</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>10</td>\n",
       "      <td>Helena</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    season   baker  episode  place  tech_mean      tech  mean_star  star  \\\n",
       "9       10   Alice       10      0   0.897436  0.916667   0.904762   0.0   \n",
       "19      10  Amelia       10     10   0.111111  0.000000   0.000000   0.0   \n",
       "29      10     Dan       10     12   0.000000  0.000000   0.000000   0.0   \n",
       "39      10   David       10      0   0.518519  0.833333   0.000000   0.0   \n",
       "49      10  Helena       10      8   0.866667  0.000000   0.000000   0.0   \n",
       "\n",
       "    mean_good  good  mean_bad  bad  \n",
       "9    0.814815   0.0  0.277778  0.0  \n",
       "19   0.000000   0.0  0.666667  0.0  \n",
       "29   0.000000   0.0  0.277778  0.0  \n",
       "39   0.909091   0.0  0.277778  0.0  \n",
       "49   0.000000   0.0  0.277778  0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbbo = pd.read_csv(\"../RESULTS/gbbo.features.s10.final.tsv\",sep=\"\\t\")\n",
    "feats = ['tech_mean','tech','mean_star','star','mean_good','good','mean_bad','bad']\n",
    "max_epi = max(gbbo['episode'])\n",
    "gbbo = gbbo.loc[gbbo['episode']==max_epi]\n",
    "gbbo = quantile_scale(gbbo,feats)\n",
    "gbbo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech = pd.read_csv(\"../RESULTS/gbbo.features.20190909.tsv\",sep='\\t')\n",
    "tech = tech.loc[tech['episode']==max_epi]\n",
    "qua = quantile_scale(tech,feats)\n",
    "qua['place']=tiered(qua['place'])\n",
    "X, y = np.matrix(qua[feats]), np.array(qua['place'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        pd.read_csv(\"../RESULTS/gbbo.features.20190909.tsv\",sep='\\t'),\n",
    "        pd.read_csv(\"../RESULTS/gbbo.features.s10.final.tsv\",sep=\"\\t\")\n",
    "    ]\n",
    ").to_csv(\"../RESULTS/deepbake_features.20201016.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-dba67ab3736c>:94: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "WARNING:tensorflow:From <ipython-input-14-dba67ab3736c>:95: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x13a2b48b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "5\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x13a5f8ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "6\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x13a7c1c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "7\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x13a961b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "8\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x13a4005e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "9\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x13a6cd820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.activations import relu\n",
    "\n",
    "def create_model( nl1=1, nl2=1,  nl3=1, \n",
    "                 nn1=1000, nn2=500, nn3 = 200, lr=0.01, decay=0., l1=0.01, l2=0.01,\n",
    "                act = 'relu', dropout=0,input_shape=None,output_shape=None):    \n",
    "    '''This is a model generating function so that we can search over neural net \n",
    "    parameters and architecture\n",
    "    https://www.kaggle.com/arrogantlymodest/randomised-cv-search-over-keras-neural-network\n",
    "    '''\n",
    "    opt = keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999,  decay=decay)\n",
    "    reg = keras.regularizers.l1_l2(l1=l1, l2=l2)\n",
    "    model = Sequential()\n",
    "    first=True  \n",
    "    for i in range(nl1):\n",
    "        if first:\n",
    "            model.add(Dense(nn1, input_dim=input_shape, activation=act, kernel_regularizer=reg))\n",
    "            first=False\n",
    "        else: \n",
    "            model.add(Dense(nn1, activation=act, kernel_regularizer=reg))\n",
    "        if dropout!=0:\n",
    "            model.add(Dropout(dropout))    \n",
    "    for i in range(nl2):\n",
    "        if first:\n",
    "            model.add(Dense(nn2, input_dim=input_shape, activation=act, kernel_regularizer=reg))\n",
    "            first=False\n",
    "        else: \n",
    "            model.add(Dense(nn2, activation=act, kernel_regularizer=reg))\n",
    "        if dropout!=0:\n",
    "            model.add(Dropout(dropout))    \n",
    "    for i in range(nl3):\n",
    "        if first:\n",
    "            model.add(Dense(nn3, input_dim=input_shape, activation=act, kernel_regularizer=reg))\n",
    "            first=False\n",
    "        else: \n",
    "            model.add(Dense(nn3, activation=act, kernel_regularizer=reg))\n",
    "        if dropout!=0:\n",
    "            model.add(Dropout(dropout))       \n",
    "    model.add(Dense(output_shape, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'],)\n",
    "    return model\n",
    "##################################\n",
    "feats = ['tech_mean','tech','mean_star','star','mean_good','good','mean_bad','bad']\n",
    "tech = pd.read_csv(\"../RESULTS/gbbo.features.20190909.tsv\",sep='\\t')\n",
    "tech['place']=tiered(tech['place'])\n",
    "input_shape = len(feats)\n",
    "output_shape = len(set(tech['place']))\n",
    "\n",
    "\n",
    "l1 = 0.0001\n",
    "l2 = 0.0001\n",
    "lr = 0.0001\n",
    "nl1 = 1\n",
    "nl2 = 1\n",
    "nl3 = 1\n",
    "nn1 = 800\n",
    "nn2 = 800\n",
    "nn3 = 300\n",
    "\n",
    "dropout = 0.1\n",
    "decay = 1e-09\n",
    "act='relu'\n",
    "n_dims = len(feats)\n",
    "n_classes = len(set(tech['place']))\n",
    "\n",
    "\n",
    "BATCH,EPOCHS = 12, 25\n",
    "####\n",
    "GBBO = pd.read_csv(\"../RESULTS/gbbo.features.s10.final.tsv\",sep=\"\\t\")\n",
    "\n",
    "for e in set(GBBO['episode']):\n",
    "    gbbo = GBBO.loc[GBBO['episode']==e]\n",
    "    gbbo = quantile_scale(gbbo,feats)\n",
    "    test = np.matrix(gbbo[feats])\n",
    "\n",
    "    tech = pd.read_csv(\"../RESULTS/gbbo.features.20190909.tsv\",sep='\\t')\n",
    "    tech = tech.loc[tech['episode']==e]\n",
    "    qua = quantile_scale(tech,feats)\n",
    "    qua['place']=tiered(qua['place'])\n",
    "    \n",
    "    X, y = np.matrix(qua[feats]), np.array(qua['place'])\n",
    "    \n",
    "    nn = create_model( nl1=nl1, nl2=nl2,  nl3=nl3, \n",
    "                     nn1=nn1, nn2=nn2, nn3 = nn3, \n",
    "                     lr=lr, decay=decay, l1=l1, l2=l2,\n",
    "                     act = act, dropout=dropout,\n",
    "                     input_shape=n_dims,\n",
    "                     output_shape=n_classes)\n",
    "    \n",
    "    nn.fit(X,y,validation_split=0., batch_size=BATCH, epochs=EPOCHS,verbose=0)\n",
    "\n",
    "    preds = nn.predict_classes(test)\n",
    "    probs = nn.predict_proba(test)\n",
    "    gbbo['preds']=preds\n",
    "    # probability baker is a finalist\n",
    "    top = probs[:,0]\n",
    "    # probability baker is a finalist or a runner-up\n",
    "    top3 = probs[:,0]+probs[:,1]\n",
    "    # bottom tier (8th and below)\n",
    "    bot = probs[:,-1]\n",
    "    # 5th - 7th\n",
    "    nextbot = probs[:,-2]\n",
    "    third = probs[:,-3]\n",
    "\n",
    "    gbbo['bottom']=np.round(bot*100,decimals=2)\n",
    "    gbbo['finalist']=np.round(top*100,decimals=2) \n",
    "    gbbo['top3'] = np.round(top3*100,decimals=2)\n",
    "    gbbo['fifthseventh'] = np.round(nextbot*100,decimals=2)\n",
    "    gbbo['thirdforth'] = np.round(third*100,decimals=2)\n",
    "\n",
    "    gbbo.to_csv(\"../RESULTS/gbbo.techinical.s10.week{}.final2.keras.preditions.txt\".format(e),sep=\"\\t\",index=False)\n",
    "    sub = ['baker','preds','finalist','top3','bottom','fifthseventh','thirdforth']\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        baker  preds   finalist       top3     bottom  fifthseventh  \\\n",
      "39      David      1  34.000000  87.599998   2.700000      5.310000   \n",
      "129     Steph      1  23.459999  98.190002   0.240000      0.900000   \n",
      "9       Alice      1  22.049999  97.610001   0.260000      1.210000   \n",
      "89   Michelle      2  11.310000  19.730000   9.740000     34.250000   \n",
      "29        Dan      4   3.840000   6.910000  61.919998     19.610001   \n",
      "99       Phil      4   3.370000   6.140000  49.419998     29.990000   \n",
      "49     Helena      3   2.850000   5.580000  23.320000     52.799999   \n",
      "59      Henry      2   2.240000   3.340000  18.580000     38.310001   \n",
      "79    Michael      3   1.550000   2.630000   4.970000     48.189999   \n",
      "19     Amelia      4   1.000000   1.670000  73.669998     17.209999   \n",
      "69      Jamie      4   1.000000   1.670000  73.669998     17.209999   \n",
      "119     Rosie      3   0.550000   0.870000  35.009998     36.650002   \n",
      "109     Priya      4   0.530000   0.900000  53.860001     34.599998   \n",
      "\n",
      "     thirdforth  \n",
      "39     4.390000  \n",
      "129    0.670000  \n",
      "9      0.920000  \n",
      "89    36.270000  \n",
      "29    11.550000  \n",
      "99    14.450000  \n",
      "49    18.309999  \n",
      "59    39.779999  \n",
      "79    44.209999  \n",
      "19     7.450000  \n",
      "69     7.450000  \n",
      "119   27.480000  \n",
      "109   10.630000  \n"
     ]
    }
   ],
   "source": [
    "gbbo = gbbo[sub].sort_values(by=['finalist'],ascending=False)\n",
    "print(gbbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
