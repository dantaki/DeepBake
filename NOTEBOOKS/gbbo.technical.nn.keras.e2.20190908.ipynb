{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bake a Deep Learning Classifier with Keras\n",
    "---------------------------------------------------\n",
    "\n",
    "Keras is a library that simplifies the construction of neural networks.\n",
    "\n",
    "This notebook will highlight how to construct a simple feed-forward neural network to predict the final rankings of bakers from episode 2.\n",
    "\n",
    "The features used in the model include the mean ranking for technical challenges and the ranking of the technical challenge for episode 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import vapeplot\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, Dropout\n",
    "from keras.activations import relu, sigmoid, tanh\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def timestamp(): return datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "def quantile_scale(df,feats):\n",
    "    qua = df\n",
    "    scaler = QuantileTransformer(\n",
    "        n_quantiles=10,\n",
    "        random_state=42,\n",
    "        ignore_implicit_zeros=True, #sparse matrix\n",
    "    )\n",
    "    # fit the scaler\n",
    "    scaler.fit(qua[feats])\n",
    "    # transform values\n",
    "    qua[feats] = scaler.transform(qua[feats])\n",
    "    return qua\n",
    "\n",
    "def calc_95ci(a,confidence=0.95):\n",
    "    a = 1.0 * np.array(a)\n",
    "    n = len(a)\n",
    "    m, se = np.nanmean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return h\n",
    "\n",
    "def return_feats(df,feats,label):\n",
    "    df = df.sample(frac=1.)\n",
    "    X = np.matrix(df[feats])\n",
    "    y = np.array(df[label])\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "episode=2\n",
    "season=7\n",
    "tech = pd.read_csv(\"../RESULTS/gbbo.techinical.data.20190907.tsv\",sep='\\t')\n",
    "\n",
    "def transform_labels(classes):\n",
    "    return np.where(classes<=7, classes, 8)\n",
    "\n",
    "def tiered(classes):\n",
    "    trans = []\n",
    "    for x in classes:\n",
    "        if x==1: c=0\n",
    "        if x==2: c=1\n",
    "        if x>=3 and x<=4: c=2\n",
    "        if x>=5 and x<=7: c=3\n",
    "        if x>=8: c=4\n",
    "        trans.append(c)\n",
    "    return trans\n",
    "\n",
    "def _4tiers(classes):\n",
    "    trans = []\n",
    "    for x in classes:\n",
    "        if x<=2: c=0\n",
    "        if x>=3 and x<=4: c=1\n",
    "        if x>=5 and x<=7: c=2\n",
    "        if x>=8: c=3\n",
    "        trans.append(c)\n",
    "    return trans\n",
    "\n",
    "classes = tiered(np.array(tech['place']))\n",
    "\n",
    "tech['place']=classes\n",
    "feats = ['tech_mean','tech']\n",
    "tech = tech.loc[tech['episode']==episode]\n",
    "\n",
    "tech = quantile_scale(tech,feats)\n",
    "X,y = return_feats(tech,feats,'place')\n",
    "X_test, y_test = return_feats(tech.loc[tech['season']==season],feats,'place')\n",
    "X_train, y_train = return_feats(tech.loc[tech['season']!=season],feats,'place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def create_model(layers, activations):\n",
    "    n_dims = X.shape[1]\n",
    "    n_classes = len(set(y))\n",
    "    model = Sequential()\n",
    "    for i,nodes in enumerate(layers):\n",
    "        if i==0:\n",
    "            model.add(Dense(n_dims,input_dim=n_dims))\n",
    "            model.add(Activation(activations))\n",
    "        else:\n",
    "            model.add(Dense(nodes))\n",
    "            model.add(Activation(activations))\n",
    "    # output layer needs to have the same number of neurons\n",
    "    # as the number of classes to predict\n",
    "    model.add(Dense(n_classes))\n",
    "    \n",
    "    # binary_crossentropy is for binary models\n",
    "    # categorical_crossentropy is for multiclass models\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "----------------------\n",
    "\n",
    "Hyperparameters are model settings that are defined before training. \n",
    "For Neural Networks, this include the learning rate, the number of hidden layers, number of neurons in hidden layers, and neuron activation functions\n",
    "\n",
    "We will evaluate the performance of a neural network across different hyperparameter conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Bakers: 5\n",
      "N Jobs: 216\n"
     ]
    }
   ],
   "source": [
    "n_dims = np.matrix(X).shape[1]\n",
    "n_classes = len(set(y))\n",
    "print('Number of Bakers: {}'.format(n_classes))\n",
    "\n",
    "#################\n",
    "# hyperparamters\n",
    "## number of hidden layers is the length of the entry\n",
    "## the value is the number of neurons for each layer\n",
    "layers= [ [100,64],[8,16,32,4], [64,128,32,4] ]\n",
    "## activation functions for neurons\n",
    "activations = ['sigmoid','relu']\n",
    "## number of times the complete dataset is passed through\n",
    "## the model. underfit if too low, overfit if too high\n",
    "epochs = [30,50]\n",
    "## size of subset for each epoch, determines the number of\n",
    "## iterations for each epoch\n",
    "batch_size = [25,50]\n",
    "################\n",
    "param_grid = dict(\n",
    "    layers=layers,\n",
    "    activations=activations,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size\n",
    "    )\n",
    "\n",
    "# Leave One (Season) Out Cross Validation\n",
    "# leave one out CV\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "loo = LeaveOneGroupOut()\n",
    "cv=loo.split(X,groups=tech['season'])\n",
    "\n",
    "grid = GridSearchCV(estimator=model,\n",
    "                    param_grid=param_grid,\n",
    "                    cv=cv,\n",
    "                    verbose=2,\n",
    "                    n_jobs=8,\n",
    "                   )\n",
    "\n",
    "# try a random search\n",
    "\n",
    "print('N Jobs:',len(layers)*len(activations)*len(epochs)*len(batch_size)*9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the Leave One Out Cross Validation over all the different combinations of hyperparameters. \n",
    "\n",
    "-------------------------------------------------\n",
    "#### This will take a while so let it bake!\n",
    "-------------------------------------------------\n",
    "\n",
    "#### Results\n",
    "\n",
    "##### Class labels 1-8\n",
    "````\n",
    "{'activations': 'sigmoid',\n",
    " 'batch_size': 50,\n",
    " 'epochs': 50,\n",
    " 'layers': [64, 128, 32, 64, 8]}\n",
    " 0.19417475786023927\n",
    " ````\n",
    " \n",
    " ----\n",
    " \n",
    " ```\n",
    " {'activations': 'sigmoid',\n",
    " 'batch_size': 50,\n",
    " 'epochs': 50,\n",
    " 'layers': [64, 128, 32]}\n",
    " 0.20388349832840336\n",
    " ```\n",
    " \n",
    " ##### Tiers\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 9 folds for each of 24 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:   43.5s\n",
      "[Parallel(n_jobs=8)]: Done 216 out of 216 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activations': 'sigmoid',\n",
       " 'batch_size': 50,\n",
       " 'epochs': 50,\n",
       " 'layers': [64, 128, 32, 4]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24271845065274286"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activations': 'sigmoid',\n",
       " 'batch_size': 50,\n",
       " 'epochs': 50,\n",
       " 'layers': [64, 128, 32]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20388349832840336"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
